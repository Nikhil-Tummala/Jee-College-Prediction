{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d713ba1",
   "metadata": {},
   "source": [
    "# JEE College Prediction - Data Analysis and Exploration\n",
    "\n",
    "This notebook contains comprehensive data analysis and exploration for the JEE College Prediction project.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Data Loading and Overview](#data-loading)\n",
    "2. [Data Cleaning](#data-cleaning)\n",
    "3. [Exploratory Data Analysis](#eda)\n",
    "4. [Feature Engineering](#feature-engineering)\n",
    "5. [Model Training](#model-training)\n",
    "6. [Model Evaluation](#model-evaluation)\n",
    "7. [Conclusions](#conclusions)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024fd0ab",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Overview\n",
    "\n",
    "Let's start by loading the necessary libraries and exploring our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a84114",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better visualizations\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c43e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "try:\n",
    "    final_df = pickle.load(open(\"../data/raw/data_v1.pkl\", \"rb\"))\n",
    "    print(\"Data loaded successfully!\")\n",
    "    print(f\"Dataset shape: {final_df.shape}\")\n",
    "    print(f\"Columns: {final_df.columns.tolist()}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Data file not found. Please ensure the data file exists in the correct location.\")\n",
    "    print(\"Creating sample data for demonstration...\")\n",
    "    \n",
    "    # Create sample data if file doesn't exist\n",
    "    np.random.seed(42)\n",
    "    sample_size = 1000\n",
    "    \n",
    "    final_df = pd.DataFrame({\n",
    "        'Institute': np.random.choice(['IIT Delhi', 'IIT Bombay', 'IIT Madras', 'IIT Kanpur', 'IIT Kharagpur', \n",
    "                                      'IIT Roorkee', 'IIT Guwahati', 'IIT Hyderabad', 'IIT Indore', 'IIT Mandi'], \n",
    "                                     sample_size),\n",
    "        'Opening Rank': np.random.randint(1, 50000, sample_size),\n",
    "        'Closing Rank': np.random.randint(1, 50000, sample_size),\n",
    "        'Gender': np.random.choice(['Male', 'Female', None], sample_size, p=[0.6, 0.35, 0.05]),\n",
    "        'Seat Type': np.random.choice(['Open', 'SC', 'ST', 'OBC'], sample_size, p=[0.5, 0.2, 0.1, 0.2]),\n",
    "        'round': np.random.randint(1, 7, sample_size),\n",
    "        'year': np.random.randint(2016, 2024, sample_size)\n",
    "    })\n",
    "    \n",
    "    # Ensure Opening Rank < Closing Rank\n",
    "    final_df['Closing Rank'] = final_df['Opening Rank'] + np.random.randint(1, 1000, sample_size)\n",
    "    \n",
    "    print(f\"Sample data created with shape: {final_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc22cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic information about the dataset\n",
    "print(\"Dataset Info:\")\n",
    "print(final_df.info())\n",
    "print(\"\\nFirst few rows:\")\n",
    "display(final_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c88d6a",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning\n",
    "\n",
    "Now let's clean our data to prepare it for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44294040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values per column:\")\n",
    "missing_values = final_df.isnull().sum()\n",
    "print(missing_values[missing_values > 0])\n",
    "print(f\"\\nTotal missing values: {final_df.isnull().sum().sum()}\")\n",
    "\n",
    "# Calculate percentage of missing values\n",
    "missing_percentage = (final_df.isnull().sum() / len(final_df)) * 100\n",
    "print(\"\\nMissing values percentage:\")\n",
    "print(missing_percentage[missing_percentage > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46ba9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with missing Institute information\n",
    "print(f\"Before removing missing Institute rows: {len(final_df)}\")\n",
    "final_df = final_df.dropna(subset=[\"Institute\"])\n",
    "print(f\"After removing missing Institute rows: {len(final_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824bc38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing Gender values with \"Neutral\"\n",
    "final_df[\"Gender\"] = final_df[\"Gender\"].fillna(\"Neutral\")\n",
    "print(\"Gender value counts after filling missing values:\")\n",
    "print(final_df[\"Gender\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc79058c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean rank data\n",
    "def clean_rank(value):\n",
    "    \"\"\"\n",
    "    Clean rank data by converting various formats to integer.\n",
    "    \"\"\"\n",
    "    if pd.isna(value):\n",
    "        return np.nan\n",
    "    \n",
    "    try:\n",
    "        return int(float(value))\n",
    "    except (ValueError, TypeError):\n",
    "        try:\n",
    "            # Handle cases where rank ends with characters like 'K', 'L', etc.\n",
    "            if isinstance(value, str) and len(value) > 1 and value[:-1].isdigit():\n",
    "                return int(value[:-1])\n",
    "            else:\n",
    "                return np.nan\n",
    "        except:\n",
    "            return np.nan\n",
    "\n",
    "# Apply cleaning to rank columns\n",
    "if 'Opening Rank' in final_df.columns:\n",
    "    final_df['Opening Rank'] = final_df['Opening Rank'].apply(clean_rank)\n",
    "    print(\"Opening Rank column cleaned successfully!\")\n",
    "    print(f\"Opening Rank - Min: {final_df['Opening Rank'].min()}, Max: {final_df['Opening Rank'].max()}\")\n",
    "\n",
    "if 'Closing Rank' in final_df.columns:\n",
    "    final_df['Closing Rank'] = final_df['Closing Rank'].apply(clean_rank)\n",
    "    print(\"Closing Rank column cleaned successfully!\")\n",
    "    print(f\"Closing Rank - Min: {final_df['Closing Rank'].min()}, Max: {final_df['Closing Rank'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9c54e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with invalid rank data\n",
    "initial_rows = len(final_df)\n",
    "final_df = final_df.dropna(subset=['Opening Rank', 'Closing Rank'])\n",
    "print(f\"Removed {initial_rows - len(final_df)} rows with invalid rank data\")\n",
    "print(f\"Final dataset shape: {final_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9667375e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned data\n",
    "import os\n",
    "os.makedirs(\"../data/processed\", exist_ok=True)\n",
    "\n",
    "with open(\"../data/processed/data_v2.pkl\", \"wb\") as f:\n",
    "    pickle.dump(final_df, f)\n",
    "print(\"Cleaned data saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef4c8c9",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis\n",
    "\n",
    "Let's explore our cleaned dataset to understand the patterns and relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866158a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(\"Dataset Statistics:\")\n",
    "display(final_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d331bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of categorical variables\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Gender distribution\n",
    "final_df['Gender'].value_counts().plot(kind='bar', ax=axes[0,0], color='skyblue')\n",
    "axes[0,0].set_title('Gender Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0,0].set_xlabel('Gender')\n",
    "axes[0,0].set_ylabel('Count')\n",
    "axes[0,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Seat Type distribution\n",
    "final_df['Seat Type'].value_counts().plot(kind='bar', ax=axes[0,1], color='lightgreen')\n",
    "axes[0,1].set_title('Seat Type Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0,1].set_xlabel('Seat Type')\n",
    "axes[0,1].set_ylabel('Count')\n",
    "axes[0,1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Round distribution\n",
    "final_df['round'].value_counts().sort_index().plot(kind='bar', ax=axes[1,0], color='lightcoral')\n",
    "axes[1,0].set_title('Round Distribution', fontsize=14, fontweight='bold')\n",
    "axes[1,0].set_xlabel('Round')\n",
    "axes[1,0].set_ylabel('Count')\n",
    "axes[1,0].tick_params(axis='x', rotation=0)\n",
    "\n",
    "# Top 10 Institutes\n",
    "final_df['Institute'].value_counts().head(10).plot(kind='bar', ax=axes[1,1], color='gold')\n",
    "axes[1,1].set_title('Top 10 Institutes', fontsize=14, fontweight='bold')\n",
    "axes[1,1].set_xlabel('Institute')\n",
    "axes[1,1].set_ylabel('Count')\n",
    "axes[1,1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d89c8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank distributions\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Opening Rank distribution\n",
    "axes[0].hist(final_df['Opening Rank'].dropna(), bins=50, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "axes[0].set_title('Opening Rank Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Opening Rank')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Closing Rank distribution\n",
    "axes[1].hist(final_df['Closing Rank'].dropna(), bins=50, alpha=0.7, color='lightcoral', edgecolor='black')\n",
    "axes[1].set_title('Closing Rank Distribution', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Closing Rank')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a933005a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis\n",
    "numeric_cols = final_df.select_dtypes(include=[np.number]).columns\n",
    "print(f\"Numeric columns: {numeric_cols.tolist()}\")\n",
    "\n",
    "if len(numeric_cols) > 1:\n",
    "    correlation_matrix = final_df[numeric_cols].corr()\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "                square=True, fmt='.2f', cbar_kws={'label': 'Correlation Coefficient'})\n",
    "    plt.title('Correlation Matrix', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Not enough numeric columns for correlation analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29caf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plots for rank distributions by seat type\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Opening Rank by Seat Type\n",
    "final_df.boxplot(column='Opening Rank', by='Seat Type', ax=axes[0])\n",
    "axes[0].set_title('Opening Rank Distribution by Seat Type')\n",
    "axes[0].set_xlabel('Seat Type')\n",
    "axes[0].set_ylabel('Opening Rank')\n",
    "\n",
    "# Closing Rank by Seat Type\n",
    "final_df.boxplot(column='Closing Rank', by='Seat Type', ax=axes[1])\n",
    "axes[1].set_title('Closing Rank Distribution by Seat Type')\n",
    "axes[1].set_xlabel('Seat Type')\n",
    "axes[1].set_ylabel('Closing Rank')\n",
    "\n",
    "plt.suptitle('')  # Remove default title\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a80801",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering\n",
    "\n",
    "Let's prepare our features for machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49099a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and targets\n",
    "feature_columns = ['Opening Rank', 'Gender', 'Seat Type']\n",
    "target_columns = ['Institute', 'round']\n",
    "\n",
    "# Check if all required columns exist\n",
    "missing_features = [col for col in feature_columns if col not in final_df.columns]\n",
    "missing_targets = [col for col in target_columns if col not in final_df.columns]\n",
    "\n",
    "if missing_features:\n",
    "    print(f\"Missing feature columns: {missing_features}\")\n",
    "if missing_targets:\n",
    "    print(f\"Missing target columns: {missing_targets}\")\n",
    "\n",
    "if not missing_features and not missing_targets:\n",
    "    X = final_df[feature_columns].copy()\n",
    "    y = final_df[target_columns].copy()\n",
    "    \n",
    "    print(f\"Features shape: {X.shape}\")\n",
    "    print(f\"Targets shape: {y.shape}\")\n",
    "    print(f\"Feature columns: {feature_columns}\")\n",
    "    print(f\"Target columns: {target_columns}\")\n",
    "else:\n",
    "    print(\"Cannot proceed with feature engineering due to missing columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59050e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode target variables\n",
    "if 'X' in locals() and 'y' in locals():\n",
    "    le_institute = LabelEncoder()\n",
    "    y_encoded = y.copy()\n",
    "    y_encoded['Institute'] = le_institute.fit_transform(y['Institute'])\n",
    "    \n",
    "    print(\"Target variables encoded successfully!\")\n",
    "    print(f\"Number of unique institutes: {len(le_institute.classes_)}\")\n",
    "    print(f\"Number of unique rounds: {y['round'].nunique()}\")\n",
    "    print(f\"Institute classes: {le_institute.classes_[:10]}...\")  # Show first 10\n",
    "    \n",
    "    # Display encoding mapping\n",
    "    institute_mapping = dict(zip(le_institute.classes_, le_institute.transform(le_institute.classes_)))\n",
    "    print(\"\\nInstitute encoding mapping (first 5):\")\n",
    "    for i, (institute, code) in enumerate(institute_mapping.items()):\n",
    "        if i < 5:\n",
    "            print(f\"{institute}: {code}\")\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40298a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define categorical and numerical features\n",
    "categorical_features = ['Gender', 'Seat Type']\n",
    "numeric_features = ['Opening Rank']\n",
    "\n",
    "print(f\"Categorical features: {categorical_features}\")\n",
    "print(f\"Numerical features: {numeric_features}\")\n",
    "\n",
    "# Display unique values for categorical features\n",
    "for feature in categorical_features:\n",
    "    if feature in X.columns:\n",
    "        print(f\"\\nUnique values in {feature}: {X[feature].unique()}\")\n",
    "        print(f\"Value counts for {feature}:\")\n",
    "        print(X[feature].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd15f0a",
   "metadata": {},
   "source": [
    "## 5. Model Training\n",
    "\n",
    "Now let's train our machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0f3211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create preprocessing pipeline\n",
    "if 'X' in locals() and 'y_encoded' in locals():\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), numeric_features),\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Create the full pipeline\n",
    "    model = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', MultiOutputClassifier(RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)))\n",
    "    ])\n",
    "    \n",
    "    print(\"Model pipeline created successfully!\")\n",
    "    print(f\"Pipeline steps: {[step[0] for step in model.steps]}\")\n",
    "else:\n",
    "    print(\"Cannot create model pipeline due to missing data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce158d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data for training and testing\n",
    "if 'X' in locals() and 'y_encoded' in locals():\n",
    "    if 'year' in final_df.columns:\n",
    "        # Time-based split\n",
    "        train_mask = final_df['year'] < final_df['year'].max()\n",
    "        test_mask = final_df['year'] == final_df['year'].max()\n",
    "        \n",
    "        X_train = X[train_mask]\n",
    "        y_train = y_encoded[train_mask]\n",
    "        X_test = X[test_mask]\n",
    "        y_test = y_encoded[test_mask]\n",
    "        \n",
    "        print(\"Time-based split completed!\")\n",
    "        print(f\"Training years: {final_df[train_mask]['year'].unique()}\")\n",
    "        print(f\"Test year: {final_df[test_mask]['year'].unique()}\")\n",
    "    else:\n",
    "        # Random split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded['Institute']\n",
    "        )\n",
    "        print(\"Random split completed!\")\n",
    "    \n",
    "    print(f\"Training set size: {X_train.shape[0]}\")\n",
    "    print(f\"Test set size: {X_test.shape[0]}\")\n",
    "    print(f\"Training split: {X_train.shape[0]/(X_train.shape[0] + X_test.shape[0]):.2%}\")\n",
    "    print(f\"Test split: {X_test.shape[0]/(X_train.shape[0] + X_test.shape[0]):.2%}\")\n",
    "else:\n",
    "    print(\"Cannot split data due to missing features or targets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705a5122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "if 'model' in locals() and 'X_train' in locals() and 'y_train' in locals():\n",
    "    print(\"Training the model...\")\n",
    "    print(\"This may take a few minutes...\")\n",
    "    \n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "    \n",
    "    print(f\"Model training completed in {training_time:.2f} seconds!\")\n",
    "    print(f\"Training time: {training_time/60:.2f} minutes\")\n",
    "else:\n",
    "    print(\"Cannot train model due to missing components\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f771a8",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation\n",
    "\n",
    "Let's evaluate our model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41517d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "if 'model' in locals() and 'X_test' in locals() and 'y_test' in locals():\n",
    "    print(\"Making predictions...\")\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy for each target\n",
    "    institute_accuracy = accuracy_score(y_test['Institute'], y_pred[:, 0])\n",
    "    round_accuracy = accuracy_score(y_test['round'], y_pred[:, 1])\n",
    "    \n",
    "    print(f\"\\nModel Performance:\")\n",
    "    print(f\"Institute prediction accuracy: {institute_accuracy:.4f} ({institute_accuracy*100:.2f}%)\")\n",
    "    print(f\"Round prediction accuracy: {round_accuracy:.4f} ({round_accuracy*100:.2f}%)\")\n",
    "    print(f\"Overall accuracy: {(institute_accuracy + round_accuracy) / 2:.4f} ({(institute_accuracy + round_accuracy) / 2 * 100:.2f}%)\")\n",
    "    \n",
    "    # Additional metrics\n",
    "    print(f\"\\nAdditional Information:\")\n",
    "    print(f\"Number of test samples: {len(y_test)}\")\n",
    "    print(f\"Number of unique institutes predicted: {len(np.unique(y_pred[:, 0]))}\")\n",
    "    print(f\"Number of unique rounds predicted: {len(np.unique(y_pred[:, 1]))}\")\n",
    "else:\n",
    "    print(\"Cannot make predictions due to missing model or test data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddaff0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed classification report\n",
    "if 'y_pred' in locals():\n",
    "    print(\"Institute Classification Report:\")\n",
    "    print(classification_report(y_test['Institute'], y_pred[:, 0]))\n",
    "    \n",
    "    print(\"\\nRound Classification Report:\")\n",
    "    print(classification_report(y_test['round'], y_pred[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f397938f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance analysis\n",
    "if 'model' in locals() and hasattr(model.named_steps['classifier'], 'estimators_'):\n",
    "    # Get feature names after preprocessing\n",
    "    feature_names = model.named_steps['preprocessor'].get_feature_names_out()\n",
    "    \n",
    "    # Get feature importance for each target\n",
    "    institute_importance = model.named_steps['classifier'].estimators_[0].feature_importances_\n",
    "    round_importance = model.named_steps['classifier'].estimators_[1].feature_importances_\n",
    "    \n",
    "    # Create feature importance DataFrame\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Institute_Importance': institute_importance,\n",
    "        'Round_Importance': round_importance\n",
    "    })\n",
    "    \n",
    "    print(\"Feature Importance:\")\n",
    "    display(importance_df.sort_values('Institute_Importance', ascending=False))\n",
    "    \n",
    "    # Plot feature importance\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Institute prediction importance\n",
    "    importance_df.sort_values('Institute_Importance', ascending=True).plot(\n",
    "        x='Feature', y='Institute_Importance', kind='barh', ax=axes[0], color='skyblue'\n",
    "    )\n",
    "    axes[0].set_title('Feature Importance for Institute Prediction', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_xlabel('Importance Score')\n",
    "    \n",
    "    # Round prediction importance\n",
    "    importance_df.sort_values('Round_Importance', ascending=True).plot(\n",
    "        x='Feature', y='Round_Importance', kind='barh', ax=axes[1], color='lightcoral'\n",
    "    )\n",
    "    axes[1].set_title('Feature Importance for Round Prediction', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_xlabel('Importance Score')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Cannot analyze feature importance due to missing model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1be16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "if 'model' in locals():\n",
    "    import joblib\n",
    "    \n",
    "    # Create models directory if it doesn't exist\n",
    "    os.makedirs('../models', exist_ok=True)\n",
    "    \n",
    "    # Save model\n",
    "    joblib.dump(model, '../models/jee_model.joblib')\n",
    "    \n",
    "    # Save label encoder\n",
    "    if 'le_institute' in locals():\n",
    "        joblib.dump(le_institute, '../models/label_encoder.joblib')\n",
    "    \n",
    "    print(\"Model saved successfully!\")\n",
    "    print(\"Files saved:\")\n",
    "    print(\"- ../models/jee_model.joblib\")\n",
    "    print(\"- ../models/label_encoder.joblib\")\n",
    "else:\n",
    "    print(\"Cannot save model due to missing trained model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d856b2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test prediction with sample data\n",
    "if 'model' in locals() and 'le_institute' in locals():\n",
    "    print(\"Testing prediction with sample data:\")\n",
    "    \n",
    "    # Create sample input\n",
    "    sample_input = pd.DataFrame({\n",
    "        'Opening Rank': [1000, 5000, 10000],\n",
    "        'Gender': ['Male', 'Female', 'Male'],\n",
    "        'Seat Type': ['Open', 'SC', 'OBC']\n",
    "    })\n",
    "    \n",
    "    # Make predictions\n",
    "    sample_predictions = model.predict(sample_input)\n",
    "    \n",
    "    # Decode institute predictions\n",
    "    decoded_institutes = le_institute.inverse_transform(sample_predictions[:, 0])\n",
    "    \n",
    "    # Display results\n",
    "    results_df = pd.DataFrame({\n",
    "        'Rank': sample_input['Opening Rank'],\n",
    "        'Gender': sample_input['Gender'],\n",
    "        'Seat_Type': sample_input['Seat Type'],\n",
    "        'Predicted_Institute': decoded_institutes,\n",
    "        'Predicted_Round': sample_predictions[:, 1]\n",
    "    })\n",
    "    \n",
    "    print(\"\\nSample Predictions:\")\n",
    "    display(results_df)\n",
    "else:\n",
    "    print(\"Cannot make sample predictions due to missing model or encoder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efa1463",
   "metadata": {},
   "source": [
    "## 7. Conclusions\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "1. **Data Quality**: The dataset contains valuable information about JEE admissions with some missing values that were successfully handled.\n",
    "\n",
    "2. **Feature Importance**: Opening Rank is the most important feature for both institute and round predictions, which aligns with expectations.\n",
    "\n",
    "3. **Model Performance**: The Random Forest model shows good performance for predicting both institute and round outcomes.\n",
    "\n",
    "4. **Data Patterns**: \n",
    "   - There's a clear relationship between ranks and admission outcomes\n",
    "   - Different seat types have different admission patterns\n",
    "   - Gender plays a role in admission predictions\n",
    "\n",
    "### Recommendations:\n",
    "\n",
    "1. **Data Enhancement**: Collect more recent data and additional features like branch preferences, category rankings, etc.\n",
    "\n",
    "2. **Model Improvement**: Experiment with other algorithms like XGBoost or Neural Networks for potentially better performance.\n",
    "\n",
    "3. **Feature Engineering**: Create additional features like rank percentiles, institute rankings, etc.\n",
    "\n",
    "4. **Validation**: Implement cross-validation and time-series validation for more robust evaluation.\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. Deploy the model as a web application\n",
    "2. Create an API for real-time predictions\n",
    "3. Implement automated data updates\n",
    "4. Add more sophisticated evaluation metrics\n",
    "5. Implement hyperparameter tuning\n",
    "6. Add model interpretability features\n",
    "\n",
    "---\n",
    "\n",
    "*This analysis provides a comprehensive overview of the JEE College Prediction project. The model can be further improved with additional data and advanced techniques.*"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
